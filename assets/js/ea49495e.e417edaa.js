"use strict";(self.webpackChunkexchron_docs=self.webpackChunkexchron_docs||[]).push([[151],{289:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"models/dnn","title":"Dual-Input Deep Neural Network (DNN)","description":"Combined time series and engineered features for robust exoplanet classification","source":"@site/docs/models/dnn.md","sourceDirName":"models","slug":"/models/dnn","permalink":"/exchron-docs/models/dnn","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"dnn","slug":"/models/dnn","title":"Dual-Input Deep Neural Network (DNN)","description":"Combined time series and engineered features for robust exoplanet classification"},"sidebar":"guideSidebar","previous":{"title":"Convolutional Neural Network (CNN)","permalink":"/exchron-docs/models/cnn"},"next":{"title":"Gradient Boosting (GB)","permalink":"/exchron-docs/models/gradient-boosting"}}');var t=i(4848),r=i(8453);const l={id:"dnn",slug:"/models/dnn",title:"Dual-Input Deep Neural Network (DNN)",description:"Combined time series and engineered features for robust exoplanet classification"},a=void 0,d={},c=[{value:"What it does",id:"what-it-does",level:2},{value:"When to use it",id:"when-to-use-it",level:2},{value:"Data needed",id:"data-needed",level:2},{value:"How the model works (simple)",id:"how-the-model-works-simple",level:2},{value:"Architecture snapshot",id:"architecture-snapshot",level:2},{value:"What you\u2019ll see (example outputs)",id:"what-youll-see-example-outputs",level:2},{value:"Typical results (example)",id:"typical-results-example",level:2},{value:"Tips",id:"tips",level:2},{value:"Highlights",id:"highlights",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Data processing",id:"data-processing",level:2},{value:"Training pipeline",id:"training-pipeline",level:2},{value:"Reported metrics (snapshot)",id:"reported-metrics-snapshot",level:2},{value:"Usage examples",id:"usage-examples",level:2},{value:"Notes",id:"notes",level:2}];function o(e){const n={code:"code",h2:"h2",img:"img",li:"li",ol:"ol",p:"p",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"This DNN combines two views of the same star: the raw light curve and a set of simple, engineered numbers about that curve. Together, they make a stronger prediction."}),"\n",(0,t.jsx)(n.h2,{id:"what-it-does",children:"What it does"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Uses the light curve to catch transit shapes"}),"\n",(0,t.jsx)(n.li,{children:"Uses features (like variability and frequency) to add context"}),"\n",(0,t.jsx)(n.li,{children:"Merges both to decide: CANDIDATE or FALSE POSITIVE"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"when-to-use-it",children:"When to use it"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"You have light curves and can compute basic features (we support 24+ common ones)"}),"\n",(0,t.jsx)(n.li,{children:"You want better accuracy and explainability than using the curve alone"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"data-needed",children:"Data needed"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Light curve CSV per star \u2192 normalized to 3000 points"}),"\n",(0,t.jsx)(n.li,{children:"Feature table per star \u2192 statistical, variability, frequency, transit features"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"how-the-model-works-simple",children:"How the model works (simple)"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Time-series branch (small CNN) learns shapes from the curve"}),"\n",(0,t.jsx)(n.li,{children:"Feature branch (dense layers) learns patterns from numbers"}),"\n",(0,t.jsx)(n.li,{children:"Both branches are merged \u2192 final dense layers \u2192 binary output"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"architecture-snapshot",children:"Architecture snapshot"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Time series: 1D conv \u2192 pooling \u2192 dropout \u2192 embedding"}),"\n",(0,t.jsx)(n.li,{children:"Features: Dense \u2192 batch norm \u2192 dropout \u2192 embedding"}),"\n",(0,t.jsx)(n.li,{children:"Merge: Concatenate \u2192 Dense \u2192 Sigmoid"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"what-youll-see-example-outputs",children:"What you\u2019ll see (example outputs)"}),"\n",(0,t.jsxs)("div",{className:"doc-images",children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Feature correlation",src:i(8955).A+"",width:"1280",height:"1162"})}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Feature importance",src:i(8824).A+"",width:"1280",height:"848"})}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Training history",src:i(6647).A+"",width:"1280",height:"956"})}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Architecture/visualization",src:i(5975).A+"",width:"1280",height:"956"})})]}),"\n",(0,t.jsx)(n.h2,{id:"typical-results-example",children:"Typical results (example)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Train \u2248 0.98 | Validation \u2248 0.97 | Test \u2248 0.96 (can vary by dataset)"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"tips",children:"Tips"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Keep preprocessing consistent between training and prediction"}),"\n",(0,t.jsx)(n.li,{children:"Use SHAP plots to understand which features matter for a given star"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"A dual-branch DNN that fuses learned features from light curve time series with engineered tabular features. The pipeline includes feature extraction, preprocessing, and comprehensive explainability via SHAP."}),"\n",(0,t.jsx)(n.h2,{id:"highlights",children:"Highlights"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Dual-input: 1) time series branch (CNN stack), 2) feature branch (dense stack)"}),"\n",(0,t.jsx)(n.li,{children:"Robust preprocessing: missing data handling, outlier removal, robust scaling"}),"\n",(0,t.jsx)(n.li,{children:"Explainability: SHAP for global and local feature importances"}),"\n",(0,t.jsx)(n.li,{children:"End-to-end training script with configuration-driven hyperparameters"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Time series branch: 1D conv + max pooling + dropout on 3000-point normalized sequences"}),"\n",(0,t.jsx)(n.li,{children:"Feature branch: Dense layers with batch norm + dropout on statistical/astronomical features"}),"\n",(0,t.jsx)(n.li,{children:"Fusion: Concatenation followed by dense layers to binary output (Candidate vs False Positive)"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"data-processing",children:"Data processing"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Light curves: normalize (median/MAD), sigma clipping, fixed length 3000"}),"\n",(0,t.jsxs)(n.li,{children:["Feature extraction: 24+ features","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Statistical: mean, std, median, skew, kurtosis"}),"\n",(0,t.jsx)(n.li,{children:"Variability: amplitude, flux excursions, range"}),"\n",(0,t.jsx)(n.li,{children:"Frequency: dominant frequency, spectral features"}),"\n",(0,t.jsx)(n.li,{children:"Transit: dip detection, periodicity"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:"KOI catalog integration, imputation, scaling"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"training-pipeline",children:"Training pipeline"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Load + preprocess sequences and features"}),"\n",(0,t.jsx)(n.li,{children:"Train/validation/test splits"}),"\n",(0,t.jsx)(n.li,{children:"Build and train model with configured hyperparameters"}),"\n",(0,t.jsx)(n.li,{children:"Evaluate metrics and generate SHAP explanations"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"reported-metrics-snapshot",children:"Reported metrics (snapshot)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Train acc: 0.9757; Val acc: 0.9669; Best val loss: 0.0797 at epoch ~59"}),"\n",(0,t.jsx)(n.li,{children:"Test acc: 0.9560 on 182 samples; features used: 12 (example snapshot)"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"usage-examples",children:"Usage examples"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Training: ",(0,t.jsx)(n.code,{children:"python train.py"})]}),"\n",(0,t.jsxs)(n.li,{children:["Config: ",(0,t.jsx)(n.code,{children:"configs/model_config.yaml"})," for architecture, training, preprocessing"]}),"\n",(0,t.jsxs)(n.li,{children:["Programmatic:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"create_dual_input_dnn_model(sequence_length=3000, feature_dim=36, ...)"})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"load_and_preprocess_data()"})," returns sequences, features, labels"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"SHAP-based explainability is integrated for model trust"}),"\n",(0,t.jsx)(n.li,{children:"Ensure consistent preprocessing for batch prediction"}),"\n",(0,t.jsx)(n.li,{children:"TensorFlow 2.x, scikit-learn, pandas, numpy, SHAP are typical dependencies"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(o,{...e})}):o(e)}},5975:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/model-visualization-data-b2a5852837659989ba99fec739aa0514.jpg"},6647:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/model-training-history-13c1ebb14e4f41a952abfa12b460cf0d.jpg"},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>a});var s=i(6540);const t={},r=s.createContext(t);function l(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(r.Provider,{value:n},e.children)}},8824:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/feature-importance-analysis-5b20163c35b7b8e42f203767b4a2ac64.jpg"},8955:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/feature-correlation-matrix-aca49e157001324d61fbe41827b8471c.jpg"}}]);